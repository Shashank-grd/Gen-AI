{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"VjYy0F2gZIPR"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","fatal: destination path 'LLaVA' already exists and is not an empty directory.\n","/content/LLaVA\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llava 1.1.1 requires transformers==4.31.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["%cd /content\n","!git clone -b v1.0 https://github.com/camenduru/LLaVA\n","%cd /content/LLaVA\n","\n","!pip install -q transformers==4.36.2\n","!pip install -q gradio .\n","\n","from transformers import AutoTokenizer, BitsAndBytesConfig\n","from llava.model import LlavaLlamaForCausalLM\n","import torch\n","\n","model_path = \"4bit/llava-v1.5-13b-3GB\"\n","kwargs = {\"device_map\": \"auto\"}\n","kwargs['load_in_4bit'] = True\n","kwargs['quantization_config'] = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type='nf4'\n",")\n","model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)\n","tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n","\n","vision_tower = model.get_vision_tower()\n","if not vision_tower.is_loaded:\n","    vision_tower.load_model()\n","vision_tower.to(device='cuda')\n","image_processor = vision_tower.image_processor\n","\n","import os\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","from llava.conversation import conv_templates, SeparatorStyle\n","from llava.utils import disable_torch_init\n","from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n","from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n","from transformers import TextStreamer\n","\n","def caption_image(image_file, prompt):\n","    if image_file.startswith('http') or image_file.startswith('https'):\n","        response = requests.get(image_file)\n","        image = Image.open(BytesIO(response.content)).convert('RGB')\n","    else:\n","        image = Image.open(image_file).convert('RGB')\n","    disable_torch_init()\n","    conv_mode = \"llava_v0\"\n","    conv = conv_templates[conv_mode].copy()\n","    roles = conv.roles\n","    image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values'].half().cuda()\n","    inp = f\"{roles[0]}: {prompt}\"\n","    inp = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + inp\n","    conv.append_message(conv.roles[0], inp)\n","    conv.append_message(conv.roles[1], None)\n","    raw_prompt = conv.get_prompt()\n","    input_ids = tokenizer_image_token(raw_prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n","    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n","    keywords = [stop_str]\n","    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n","    with torch.inference_mode():\n","      output_ids = model.generate(input_ids, images=image_tensor, do_sample=True, temperature=0.2,\n","                                  max_new_tokens=1024, use_cache=True, stopping_criteria=[stopping_criteria])\n","    outputs = tokenizer.decode(output_ids[0, input_ids.shape[1]:]).strip()\n","    conv.messages[-1][-1] = outputs\n","    output = outputs.rsplit('\u003c/s\u003e', 1)[0]\n","    return image, output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":478,"status":"ok","timestamp":1726689948099,"user":{"displayName":"shashank kumar","userId":"03790993527836558490"},"user_tz":-330},"id":"fdBxwRUUa6N1","outputId":"c5ea296b-0949-4ab6-c570-bd4b1f6071a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-09-18 20:05:47--  https://huggingface.co/camenduru/polaroid/resolve/main/style_name_fix.zip\n","Resolving huggingface.co (huggingface.co)... 3.165.160.12, 3.165.160.61, 3.165.160.59, ...\n","Connecting to huggingface.co (huggingface.co)|3.165.160.12|:443... connected.\n","HTTP request sent, awaiting response... 401 Unauthorized\n","\n","Username/Password Authentication Failed.\n","unzip:  cannot find or open style_name_fix.zip, style_name_fix.zip.zip or style_name_fix.zip.ZIP.\n"]}],"source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","!mkdir /content/images\n","!wget --header 'Authorization: Bearer TOKEN_HERE' https://huggingface.co/camenduru/polaroid/resolve/main/style_name_fix.zip\n","!unzip style_name_fix.zip -d /content/images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47935,"status":"ok","timestamp":1726691457350,"user":{"displayName":"shashank kumar","userId":"03790993527836558490"},"user_tz":-330},"id":"sma6Cfjpa6N2","outputId":"1d39a668-dbe1-4421-9c50-9429e73eb828"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error processing .ipynb_checkpoints: [Errno 21] Is a directory: '/content/images/.ipynb_checkpoints'\n","The class name for this image is \"Flower.\"\n","The class name for this image could be \"Autumn Road\" or \"Fall Highway,\" as it captures the essence of the scene with trees, leaves, and a wet road during the autumn season.\n","The class name for this image could be \"Autumn Leaves\" or \"Fallen Leaves.\"\n","The class name for this image is \"Zebra.\"\n","The class name for this image could be \"Colorful Painted Girl\" or \"Smiling Child with Paint on Fingers.\"\n","The class name for this image could be \"Hinduism\" or \"Religion\" as it features a Hindu deity, Lord Shiva, sitting in a meditative pose with a snake around his neck. The image also includes a trident, which is a symbol associated with Lord Shiva. The blue background and the overall composition of the image suggest a focus on spirituality and religious symbolism.\n","The class name for this image could be \"Alpine Flower Field\" or \"Snowy Mountain with Pink Flowers.\"\n","The class name for this image is \"Car.\"\n","The class name for this image could be \"Taj Mahal\" or \"Taj Mahal Palace.\" The Taj Mahal is a famous palace in India, known for its intricate architecture and beautiful gardens. The image features a palace with a reflecting pool, which is a common feature in the Taj Mahal's design.\n","The class name for this image is \"Play Store Icon.\"\n"]}],"source":["file_names = os.listdir('/content/images')\n","sorted_file_names = sorted(file_names)\n","for file_name in sorted_file_names:\n","    try:\n","        image, output = caption_image(f'/content/images/{file_name}', 'Describe the class name for this images.')\n","        print(output)\n","        # image\n","    except Exception as e:\n","        print(f\"Error processing {file_name}: {str(e)}\")\n","        continue"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"https://github.com/camenduru/LLaVA-colab/blob/main/LLaVA_13b_4bit_caption_colab.ipynb","timestamp":1726687025382}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}